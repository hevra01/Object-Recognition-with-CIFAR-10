{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec9071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import torch\n",
    "torch.manual_seed(0) \n",
    "import torch.nn as nn # more object oriented\n",
    "import torch.nn.functional as F # more functional\n",
    "# torchvision is used for image and video transformations. It also has its own datasets.\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import torch.optim as optim\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4434f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10 # torchvision has its own datasets so we can import from there directly\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# preprocessing (normalization) of the training data\n",
    "train_transform = T. Compose ([\n",
    "# can add additional transforms on images\n",
    "T. ToTensor () , # convert images to PyTorch tensors, which are arrays\n",
    "T. Grayscale () , # RGB to grayscale\n",
    "T. Normalize ( mean =(0.5 ,) , std=(0.5 ,) ) # normalization\n",
    "# speeds up the convergence\n",
    "# and improves the accuracy\n",
    "])\n",
    "\n",
    "# preprocessing (normalization) of the testing data\n",
    "val_transform = test_transform = T. Compose ([\n",
    "T. ToTensor () ,\n",
    "T. Grayscale () ,\n",
    "T. Normalize ( mean =(0.5 ,) , std=(0.5 ,) )\n",
    "])\n",
    "\n",
    "\n",
    "# downloading our data separately for both the train and test sets and apply the transformation (preprocessing) on it.\n",
    "train_set = CIFAR10 ( root = 'CIFAR10', train =True ,transform = train_transform , download = True )\n",
    "test_set = CIFAR10 ( root = 'CIFAR10', train =False , transform = test_transform , download = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b125e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the validation and training set. validation set is used to tune \n",
    "# the hyper-parameters, e.g learning-rate, number of hidden layers, etc.\n",
    "# we do the separation before creating batches of the train and test set \n",
    "# 80 percent of the train_set will be kept as the train set and 20 percent will be used as the validation.\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "trainset, validationset = torch.utils.data.random_split(train_set, [train_set_size, valid_set_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5765140d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide our data into batches and shuffle them.\n",
    "trainset = DataLoader(trainset, batch_size = 5, shuffle=True)\n",
    "testset = DataLoader(test_set, batch_size = 5, shuffle=True)\n",
    "validationset = DataLoader(validationset, batch_size = 5, shuffle=True) \n",
    "\n",
    "# specify the classes\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', \n",
    "            'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c9843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4014, 1: 4002, 2: 3995, 3: 3977, 4: 3982, 5: 4019, 6: 3975, 7: 4010, 8: 4010, 9: 4016}\n"
     ]
    }
   ],
   "source": [
    "# count the number of varying objects\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    xs, ys = data # input and its label\n",
    "    for y in ys: \n",
    "        # count the number of individual objects inside the dataset\n",
    "        counter_dict[int(y)] += 1 \n",
    "        total+=1\n",
    "        \n",
    "# it is observed that they are all equally present\n",
    "# so our data set is balanced.\n",
    "print(counter_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8e08f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (deep_nn): Sequential(\n",
      "    (ff0): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (ff1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# this is our neural network!!\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hidden_layers, hidden_layer_size):\n",
    "        super(NeuralNet, self).__init__() # initialize the super class \n",
    "        \n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.deep_nn = nn.Sequential()\n",
    "        \n",
    "        # creating the input and the hidden layers. the activation function used is relu.\n",
    "        for i in range(num_hidden_layers + 1):\n",
    "            self.deep_nn.add_module(f'ff{i}', nn.Linear(input_size, hidden_layer_size))\n",
    "            # after creating the input layer, the value of input_size needs to change\n",
    "            input_size = hidden_layer_size \n",
    "            \n",
    "        self.deep_nn.add_module(f'classifier', nn.Linear(hidden_layer_size, output_size))\n",
    "   \n",
    "    # passing of the data\n",
    "    def forward(self, data, activation_func):\n",
    "        # the activation function for the input and the hidden layers is relu\n",
    "        for i in range((self.num_hidden_layers) + 1):\n",
    "            if activation_func == 'relu':\n",
    "                data = F.relu(self.deep_nn[i](data))\n",
    "            elif activation_func == 'sigmoid':\n",
    "                data = F.sigmoid(self.deep_nn[i](data))\n",
    "            elif activation_func == 'Tanh':\n",
    "                data = F.tanh(self.deep_nn[i](data))\n",
    "        # the activation function for the output layer is softmax but we aren't going to initialize that now\n",
    "        # because the loss function crossEntropyLoss already applies softmax.\n",
    "        return data\n",
    "    \n",
    "    # loss function is used to measure how well the model (neural network) is doing\n",
    "    # On the other hand, the optimizer tries to adjust the weights and biases in such a way to minimize the loss function.\n",
    "    def training_the_model(self, learning_rate, activation_func, trainset):\n",
    "        # we chose Adam as our optimizer.\n",
    "        # the first argument we passed in is the list of parameters that we want the optimizer to work on.\n",
    "        # e.g if we want out optimizer to only adjust some weights and not the others, we can control that here.\n",
    "        # the second argument specifies the learning rate.\n",
    "        optimizer = optim.Adam(self.parameters(), learning_rate)\n",
    "\n",
    "        # Epoch is a pass through the whole data\n",
    "        EPOCHS = 3\n",
    "        # choosing our loss function\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        for epoch in range(EPOCHS):\n",
    "            # data is a batch of featuresets and labels\n",
    "            for data in trainset: \n",
    "                # here we are separating the featureset and labels\n",
    "                X, y = data\n",
    "                # pass our input through the neural network\n",
    "                # view(-1) flattens a tensor in PyTorch = brings all the rows one after another\n",
    "                output = self.forward(X.view(-1, 32*32), activation_func)\n",
    "                # calculate the loss by comparing the model's predicted guess and the actual label\n",
    "                # the crossEntropyLoss was the loss function that we were required to use.\n",
    "                l = loss(output, y)\n",
    "                l.backward()\n",
    "                # this will adjust the weights\n",
    "                # step() makes the optimizer iterate over all parameters (tensors) it is supposed to update \n",
    "                # and use their internally stored grad to update their values.\n",
    "                optimizer.step() \n",
    "            \n",
    "    def evaluatingModel(self, validationset, activation_funct):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        lossTotal = 0\n",
    "\n",
    "        # choosing our loss function\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # data is a batch of featuresets and labels\n",
    "            for data in validationset:\n",
    "                X, y = data\n",
    "                output = self.forward(X.view(-1, 32*32), activation_funct)\n",
    "                # here we are evaluating our model. basically, comparing the models guess to the actual y value\n",
    "                for idx, i in enumerate(output):\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1 # increment correct if the model has guessed correctly\n",
    "                    total += 1\n",
    "                # find the loss for each batch and add it to the total loss.\n",
    "                lossTotal += loss(self.forward(X.view(-1, 32*32), activation_funct), y)\n",
    "\n",
    "        #print(\"Accuracy: \", round(correct/total, 3))\n",
    "        # to get the average loss, divide the total loss by the number of batches\n",
    "        loss = lossTotal / len(validationset)\n",
    "        #print(\"Loss: \", loss)\n",
    "        return round(correct/total, 3), loss\n",
    "            \n",
    "        \n",
    "        \n",
    "net = NeuralNet(32*32, 10, 1, 64)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943acad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.001\n",
      "Loss:  tensor(4.1862)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "# This is used to see the value of the accuracy and loss on the untrained network and compare it to my guess.\n",
    "correct = 0\n",
    "total = 0\n",
    "lossTotal = 0\n",
    "\n",
    "# choosing our loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # data is a batch of featuresets and labels\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net.forward(X.view(-1, 32*32), 'relu')\n",
    "        # here we are evaluating our model. basically, comparing the models guess to the actual y value\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1 # increment correct if the model has guessed correctly\n",
    "            total += 1\n",
    "        # find the loss for each batch and add it to the total loss.\n",
    "        lossTotal += loss(net.forward(X.view(-1, 32*32), 'relu'), y)\n",
    "        \n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "# to get the average loss, divide the total loss by the number of batches\n",
    "loss = lossTotal / len(trainset)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a162a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.208 tensor(121.3431)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hevra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099 tensor(5.4362)\n",
      "0.099 tensor(5.5328)\n",
      "0.1 tensor(5.7947)\n",
      "0.099 tensor(5.8370)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hevra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.126 tensor(5.7092)\n",
      "0.14 tensor(5.9062)\n",
      "0.118 tensor(6.0550)\n",
      "0.11 tensor(6.4352)\n",
      "0.139 tensor(5.4457)\n",
      "0.128 tensor(5.6002)\n",
      "0.129 tensor(5.8242)\n",
      "0.128 tensor(5.9480)\n",
      "0.128 tensor(5.2419)\n",
      "0.132 tensor(5.4468)\n",
      "0.127 tensor(5.5980)\n",
      "0.142 tensor(5.7529)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.102 tensor(4.3570)\n",
      "0.099 tensor(5.0754)\n",
      "0.102 tensor(4.1485)\n",
      "0.098 tensor(5.0593)\n",
      "0.099 tensor(5.2414)\n",
      "0.099 tensor(5.6346)\n",
      "0.101 tensor(5.8919)\n",
      "0.099 tensor(5.9332)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.13 tensor(5.8429)\n",
      "0.129 tensor(5.9153)\n",
      "0.112 tensor(6.1754)\n",
      "0.131 tensor(6.3411)\n",
      "0.136 tensor(5.5349)\n",
      "0.13 tensor(5.6510)\n",
      "0.131 tensor(5.8278)\n",
      "0.132 tensor(6.0264)\n",
      "0.135 tensor(5.2513)\n",
      "0.117 tensor(5.4398)\n",
      "0.143 tensor(5.7263)\n",
      "0.137 tensor(5.7939)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(4.2383)\n",
      "0.11 tensor(5.2497)\n",
      "0.099 tensor(3.9313)\n",
      "0.101 tensor(3.5275)\n",
      "0.1 tensor(5.4337)\n",
      "0.099 tensor(5.5317)\n",
      "0.099 tensor(5.6968)\n",
      "0.099 tensor(6.0312)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.08 tensor(5.9805)\n",
      "0.126 tensor(6.3734)\n",
      "0.133 tensor(6.2311)\n",
      "0.11 tensor(6.4522)\n",
      "0.131 tensor(5.6902)\n",
      "0.07 tensor(6.0545)\n",
      "0.13 tensor(6.0365)\n",
      "0.131 tensor(6.3177)\n",
      "0.142 tensor(5.2848)\n",
      "0.14 tensor(5.5265)\n",
      "0.131 tensor(5.6948)\n",
      "0.127 tensor(5.8521)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(2.9630)\n",
      "0.099 tensor(3.8683)\n",
      "0.099 tensor(87.0699)\n",
      "0.098 tensor(4.8177)\n",
      "0.1 tensor(5.3402)\n",
      "0.099 tensor(5.6309)\n",
      "0.1 tensor(5.5990)\n",
      "0.1 tensor(5.8391)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.069 tensor(6.3817)\n",
      "0.151 tensor(6.0986)\n",
      "0.114 tensor(6.6526)\n",
      "0.124 tensor(6.4209)\n",
      "0.123 tensor(5.8210)\n",
      "0.133 tensor(6.1147)\n",
      "0.143 tensor(6.1364)\n",
      "0.144 tensor(6.3640)\n",
      "0.127 tensor(5.4174)\n",
      "0.145 tensor(5.8059)\n",
      "0.135 tensor(5.7449)\n",
      "0.088 tensor(6.1006)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.099 tensor(6.1093)\n",
      "0.099 tensor(6.3098)\n",
      "0.099 tensor(6.4769)\n",
      "0.099 tensor(6.6201)\n",
      "0.102 tensor(3.4030)\n",
      "0.1 tensor(4.7049)\n",
      "0.099 tensor(853.4628)\n",
      "0.1 tensor(2.9840)\n",
      "0.099 tensor(5.4349)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5988)\n",
      "0.1 tensor(5.9335)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.099 tensor(5.1466)\n",
      "0.099 tensor(5.3407)\n",
      "0.099 tensor(5.5030)\n",
      "0.099 tensor(5.6426)\n",
      "0.116 tensor(6.3578)\n",
      "0.125 tensor(5.9768)\n",
      "0.125 tensor(6.3534)\n",
      "0.11 tensor(6.4959)\n",
      "0.132 tensor(6.3734)\n",
      "0.129 tensor(6.0588)\n",
      "0.077 tensor(5.9652)\n",
      "0.072 tensor(6.9360)\n",
      "0.138 tensor(5.4385)\n",
      "0.12 tensor(5.7191)\n",
      "0.127 tensor(6.0974)\n",
      "0.131 tensor(5.9914)\n"
     ]
    }
   ],
   "source": [
    "# in this cell, we will do grid search for the hyper-parameters\n",
    "# in the neuralNet we can change the # of hidden layers, # of neurons\n",
    "# i research about it and it was said that the # of neurons in the hidden layer \n",
    "# is approx. equal to (2/3) * # of neurons in the hidden layer, hence I chose the below values\n",
    "# this dictionary will store the value of the validation_accuracy and validation_loss based on the hyper-parameters\n",
    "grid_dictionary = {}\n",
    "# initialization of the hyper-parameters\n",
    "amount_of_neurons = [450, 550, 650, 750] \n",
    "activation_functions = ['relu', 'sigmoid', 'Tanh']\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "# for loop to iterate over every combination of the hyper-parameters\n",
    "for no_layer in range(5):\n",
    "    for activation_func in activation_functions:\n",
    "        for learning_rate in learning_rates:\n",
    "            for no_neurons in amount_of_neurons:\n",
    "                net = NeuralNet(32*32, 10, no_layer+1, no_neurons)\n",
    "                net.training_the_model(learning_rate, activation_func, trainset)\n",
    "                validation_accuracy, validation_loss = net.evaluatingModel(validationset, activation_func) \n",
    "                print(validation_accuracy, validation_loss)\n",
    "                grid_dictionary[no_layer+1, activation_func, learning_rate, no_neurons] = [validation_accuracy, validation_loss]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c4f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 'relu', 0.01, 450): [0.099, tensor(6.1093)], (1, 'relu', 0.01, 550): [0.099, tensor(6.3098)], (1, 'relu', 0.01, 650): [0.099, tensor(6.4769)], (1, 'relu', 0.01, 750): [0.099, tensor(6.6201)], (1, 'relu', 0.001, 450): [0.099, tensor(6.1093)], (1, 'relu', 0.001, 550): [0.099, tensor(6.3098)], (1, 'relu', 0.001, 650): [0.099, tensor(6.4769)], (1, 'relu', 0.001, 750): [0.099, tensor(6.6201)], (1, 'relu', 0.0001, 450): [0.099, tensor(6.1093)], (1, 'relu', 0.0001, 550): [0.208, tensor(121.3431)], (1, 'relu', 0.0001, 650): [0.099, tensor(6.4769)], (1, 'relu', 0.0001, 750): [0.099, tensor(6.6201)], (1, 'sigmoid', 0.01, 450): [0.099, tensor(5.4362)], (1, 'sigmoid', 0.01, 550): [0.099, tensor(5.5328)], (1, 'sigmoid', 0.01, 650): [0.1, tensor(5.7947)], (1, 'sigmoid', 0.01, 750): [0.099, tensor(5.8370)], (1, 'sigmoid', 0.001, 450): [0.099, tensor(5.1466)], (1, 'sigmoid', 0.001, 550): [0.099, tensor(5.3407)], (1, 'sigmoid', 0.001, 650): [0.099, tensor(5.5030)], (1, 'sigmoid', 0.001, 750): [0.099, tensor(5.6426)], (1, 'sigmoid', 0.0001, 450): [0.099, tensor(5.1466)], (1, 'sigmoid', 0.0001, 550): [0.099, tensor(5.3407)], (1, 'sigmoid', 0.0001, 650): [0.099, tensor(5.5030)], (1, 'sigmoid', 0.0001, 750): [0.099, tensor(5.6426)], (1, 'Tanh', 0.01, 450): [0.126, tensor(5.7092)], (1, 'Tanh', 0.01, 550): [0.14, tensor(5.9062)], (1, 'Tanh', 0.01, 650): [0.118, tensor(6.0550)], (1, 'Tanh', 0.01, 750): [0.11, tensor(6.4352)], (1, 'Tanh', 0.001, 450): [0.139, tensor(5.4457)], (1, 'Tanh', 0.001, 550): [0.128, tensor(5.6002)], (1, 'Tanh', 0.001, 650): [0.129, tensor(5.8242)], (1, 'Tanh', 0.001, 750): [0.128, tensor(5.9480)], (1, 'Tanh', 0.0001, 450): [0.128, tensor(5.2419)], (1, 'Tanh', 0.0001, 550): [0.132, tensor(5.4468)], (1, 'Tanh', 0.0001, 650): [0.127, tensor(5.5980)], (1, 'Tanh', 0.0001, 750): [0.142, tensor(5.7529)], (2, 'relu', 0.01, 450): [0.099, tensor(6.1093)], (2, 'relu', 0.01, 550): [0.099, tensor(6.3098)], (2, 'relu', 0.01, 650): [0.099, tensor(6.4769)], (2, 'relu', 0.01, 750): [0.099, tensor(6.6201)], (2, 'relu', 0.001, 450): [0.099, tensor(6.1093)], (2, 'relu', 0.001, 550): [0.099, tensor(6.3098)], (2, 'relu', 0.001, 650): [0.099, tensor(6.4769)], (2, 'relu', 0.001, 750): [0.099, tensor(6.6201)], (2, 'relu', 0.0001, 450): [0.102, tensor(4.3570)], (2, 'relu', 0.0001, 550): [0.099, tensor(5.0754)], (2, 'relu', 0.0001, 650): [0.102, tensor(4.1485)], (2, 'relu', 0.0001, 750): [0.098, tensor(5.0593)], (2, 'sigmoid', 0.01, 450): [0.099, tensor(5.2414)], (2, 'sigmoid', 0.01, 550): [0.099, tensor(5.6346)], (2, 'sigmoid', 0.01, 650): [0.101, tensor(5.8919)], (2, 'sigmoid', 0.01, 750): [0.099, tensor(5.9332)], (2, 'sigmoid', 0.001, 450): [0.099, tensor(5.1466)], (2, 'sigmoid', 0.001, 550): [0.099, tensor(5.3407)], (2, 'sigmoid', 0.001, 650): [0.099, tensor(5.5030)], (2, 'sigmoid', 0.001, 750): [0.099, tensor(5.6426)], (2, 'sigmoid', 0.0001, 450): [0.099, tensor(5.1466)], (2, 'sigmoid', 0.0001, 550): [0.099, tensor(5.3407)], (2, 'sigmoid', 0.0001, 650): [0.099, tensor(5.5030)], (2, 'sigmoid', 0.0001, 750): [0.099, tensor(5.6426)], (2, 'Tanh', 0.01, 450): [0.13, tensor(5.8429)], (2, 'Tanh', 0.01, 550): [0.129, tensor(5.9153)], (2, 'Tanh', 0.01, 650): [0.112, tensor(6.1754)], (2, 'Tanh', 0.01, 750): [0.131, tensor(6.3411)], (2, 'Tanh', 0.001, 450): [0.136, tensor(5.5349)], (2, 'Tanh', 0.001, 550): [0.13, tensor(5.6510)], (2, 'Tanh', 0.001, 650): [0.131, tensor(5.8278)], (2, 'Tanh', 0.001, 750): [0.132, tensor(6.0264)], (2, 'Tanh', 0.0001, 450): [0.135, tensor(5.2513)], (2, 'Tanh', 0.0001, 550): [0.117, tensor(5.4398)], (2, 'Tanh', 0.0001, 650): [0.143, tensor(5.7263)], (2, 'Tanh', 0.0001, 750): [0.137, tensor(5.7939)], (3, 'relu', 0.01, 450): [0.099, tensor(6.1093)], (3, 'relu', 0.01, 550): [0.099, tensor(6.3098)], (3, 'relu', 0.01, 650): [0.099, tensor(6.4769)], (3, 'relu', 0.01, 750): [0.099, tensor(6.6201)], (3, 'relu', 0.001, 450): [0.099, tensor(6.1093)], (3, 'relu', 0.001, 550): [0.099, tensor(6.3098)], (3, 'relu', 0.001, 650): [0.099, tensor(6.4769)], (3, 'relu', 0.001, 750): [0.099, tensor(6.6201)], (3, 'relu', 0.0001, 450): [0.099, tensor(4.2383)], (3, 'relu', 0.0001, 550): [0.11, tensor(5.2497)], (3, 'relu', 0.0001, 650): [0.099, tensor(3.9313)], (3, 'relu', 0.0001, 750): [0.101, tensor(3.5275)], (3, 'sigmoid', 0.01, 450): [0.1, tensor(5.4337)], (3, 'sigmoid', 0.01, 550): [0.099, tensor(5.5317)], (3, 'sigmoid', 0.01, 650): [0.099, tensor(5.6968)], (3, 'sigmoid', 0.01, 750): [0.099, tensor(6.0312)], (3, 'sigmoid', 0.001, 450): [0.099, tensor(5.1466)], (3, 'sigmoid', 0.001, 550): [0.099, tensor(5.3407)], (3, 'sigmoid', 0.001, 650): [0.099, tensor(5.5030)], (3, 'sigmoid', 0.001, 750): [0.099, tensor(5.6426)], (3, 'sigmoid', 0.0001, 450): [0.099, tensor(5.1466)], (3, 'sigmoid', 0.0001, 550): [0.099, tensor(5.3407)], (3, 'sigmoid', 0.0001, 650): [0.099, tensor(5.5030)], (3, 'sigmoid', 0.0001, 750): [0.099, tensor(5.6426)], (3, 'Tanh', 0.01, 450): [0.08, tensor(5.9805)], (3, 'Tanh', 0.01, 550): [0.126, tensor(6.3734)], (3, 'Tanh', 0.01, 650): [0.133, tensor(6.2311)], (3, 'Tanh', 0.01, 750): [0.11, tensor(6.4522)], (3, 'Tanh', 0.001, 450): [0.131, tensor(5.6902)], (3, 'Tanh', 0.001, 550): [0.07, tensor(6.0545)], (3, 'Tanh', 0.001, 650): [0.13, tensor(6.0365)], (3, 'Tanh', 0.001, 750): [0.131, tensor(6.3177)], (3, 'Tanh', 0.0001, 450): [0.142, tensor(5.2848)], (3, 'Tanh', 0.0001, 550): [0.14, tensor(5.5265)], (3, 'Tanh', 0.0001, 650): [0.131, tensor(5.6948)], (3, 'Tanh', 0.0001, 750): [0.127, tensor(5.8521)], (4, 'relu', 0.01, 450): [0.099, tensor(6.1093)], (4, 'relu', 0.01, 550): [0.099, tensor(6.3098)], (4, 'relu', 0.01, 650): [0.099, tensor(6.4769)], (4, 'relu', 0.01, 750): [0.099, tensor(6.6201)], (4, 'relu', 0.001, 450): [0.099, tensor(6.1093)], (4, 'relu', 0.001, 550): [0.099, tensor(6.3098)], (4, 'relu', 0.001, 650): [0.099, tensor(6.4769)], (4, 'relu', 0.001, 750): [0.099, tensor(6.6201)], (4, 'relu', 0.0001, 450): [0.099, tensor(2.9630)], (4, 'relu', 0.0001, 550): [0.099, tensor(3.8683)], (4, 'relu', 0.0001, 650): [0.099, tensor(87.0699)], (4, 'relu', 0.0001, 750): [0.098, tensor(4.8177)], (4, 'sigmoid', 0.01, 450): [0.1, tensor(5.3402)], (4, 'sigmoid', 0.01, 550): [0.099, tensor(5.6309)], (4, 'sigmoid', 0.01, 650): [0.1, tensor(5.5990)], (4, 'sigmoid', 0.01, 750): [0.1, tensor(5.8391)], (4, 'sigmoid', 0.001, 450): [0.099, tensor(5.1466)], (4, 'sigmoid', 0.001, 550): [0.099, tensor(5.3407)], (4, 'sigmoid', 0.001, 650): [0.099, tensor(5.5030)], (4, 'sigmoid', 0.001, 750): [0.099, tensor(5.6426)], (4, 'sigmoid', 0.0001, 450): [0.099, tensor(5.1466)], (4, 'sigmoid', 0.0001, 550): [0.099, tensor(5.3407)], (4, 'sigmoid', 0.0001, 650): [0.099, tensor(5.5030)], (4, 'sigmoid', 0.0001, 750): [0.099, tensor(5.6426)], (4, 'Tanh', 0.01, 450): [0.069, tensor(6.3817)], (4, 'Tanh', 0.01, 550): [0.151, tensor(6.0986)], (4, 'Tanh', 0.01, 650): [0.114, tensor(6.6526)], (4, 'Tanh', 0.01, 750): [0.124, tensor(6.4209)], (4, 'Tanh', 0.001, 450): [0.123, tensor(5.8210)], (4, 'Tanh', 0.001, 550): [0.133, tensor(6.1147)], (4, 'Tanh', 0.001, 650): [0.143, tensor(6.1364)], (4, 'Tanh', 0.001, 750): [0.144, tensor(6.3640)], (4, 'Tanh', 0.0001, 450): [0.127, tensor(5.4174)], (4, 'Tanh', 0.0001, 550): [0.145, tensor(5.8059)], (4, 'Tanh', 0.0001, 650): [0.135, tensor(5.7449)], (4, 'Tanh', 0.0001, 750): [0.088, tensor(6.1006)], (5, 'relu', 0.01, 450): [0.099, tensor(6.1093)], (5, 'relu', 0.01, 550): [0.099, tensor(6.3098)], (5, 'relu', 0.01, 650): [0.099, tensor(6.4769)], (5, 'relu', 0.01, 750): [0.099, tensor(6.6201)], (5, 'relu', 0.001, 450): [0.099, tensor(6.1093)], (5, 'relu', 0.001, 550): [0.099, tensor(6.3098)], (5, 'relu', 0.001, 650): [0.099, tensor(6.4769)], (5, 'relu', 0.001, 750): [0.099, tensor(6.6201)], (5, 'relu', 0.0001, 450): [0.102, tensor(3.4030)], (5, 'relu', 0.0001, 550): [0.1, tensor(4.7049)], (5, 'relu', 0.0001, 650): [0.099, tensor(853.4628)], (5, 'relu', 0.0001, 750): [0.1, tensor(2.9840)], (5, 'sigmoid', 0.01, 450): [0.099, tensor(5.4349)], (5, 'sigmoid', 0.01, 550): [0.099, tensor(5.3407)], (5, 'sigmoid', 0.01, 650): [0.099, tensor(5.5988)], (5, 'sigmoid', 0.01, 750): [0.1, tensor(5.9335)], (5, 'sigmoid', 0.001, 450): [0.099, tensor(5.1466)], (5, 'sigmoid', 0.001, 550): [0.099, tensor(5.3407)], (5, 'sigmoid', 0.001, 650): [0.099, tensor(5.5030)], (5, 'sigmoid', 0.001, 750): [0.099, tensor(5.6426)], (5, 'sigmoid', 0.0001, 450): [0.099, tensor(5.1466)], (5, 'sigmoid', 0.0001, 550): [0.099, tensor(5.3407)], (5, 'sigmoid', 0.0001, 650): [0.099, tensor(5.5030)], (5, 'sigmoid', 0.0001, 750): [0.099, tensor(5.6426)], (5, 'Tanh', 0.01, 450): [0.116, tensor(6.3578)], (5, 'Tanh', 0.01, 550): [0.125, tensor(5.9768)], (5, 'Tanh', 0.01, 650): [0.125, tensor(6.3534)], (5, 'Tanh', 0.01, 750): [0.11, tensor(6.4959)], (5, 'Tanh', 0.001, 450): [0.132, tensor(6.3734)], (5, 'Tanh', 0.001, 550): [0.129, tensor(6.0588)], (5, 'Tanh', 0.001, 650): [0.077, tensor(5.9652)], (5, 'Tanh', 0.001, 750): [0.072, tensor(6.9360)], (5, 'Tanh', 0.0001, 450): [0.138, tensor(5.4385)], (5, 'Tanh', 0.0001, 550): [0.12, tensor(5.7191)], (5, 'Tanh', 0.0001, 650): [0.127, tensor(6.0974)], (5, 'Tanh', 0.0001, 750): [0.131, tensor(5.9914)]}\n"
     ]
    }
   ],
   "source": [
    "print(grid_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de80ca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hevra\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hevra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from setuptools-scm>=4->matplotlib) (58.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75133a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
